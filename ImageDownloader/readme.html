<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Untitled Document</title>
<style type="text/css">
.color1 {
	color: #008040;
}
body {
	background-color: #FFF;
}
</style>
</head>

<body>
<h2 align="center"><u>Image Downloader</u></h2>
<p align="center">ImageNET link listing</p>

<div align="center">
  <table width="50%" border="0">
    <tr>
      <td><p><u><strong>Description:</strong></u></p>
        <p>This is a simple tool that was written  in order to download image sets for AI purposes. It takes a noun subset of the ImageNET links list and the uses a multi-threaded approach to downloading them. Below is a set of instructions on how to use the tool as well as a list of known problems.</p>
        <p><u><strong>How to use:</strong></u></p>
        <p>Once you have everything in a directory you'll need to get the picture links which can be downloaded here:<a href="http://www.slogmore.com/pic_links.rar">http://www.slogmore.com/pic_links.rar</a></p>
        <p>Unpack this in the same directory as the Python files.</p>
        <p>The simplest way to run the program is in following fashion: </p>
        <blockquote>
          <p class="color1">python imagenetdl.py [search_term] </p>
        </blockquote>
        <p>Which will find all the search_terms from the search_terms.txt file and then download the corresponding images found in the pic_links directory. <br />
        </p>
        <p>The program can also be run with the following parameters:</p>
        <p><span class="color1">[-t ] </span>Which specifies the max number of threads. The default is 50<span class="color1">.</span></p>
        <p><span class="color1">[-d] </span>Specifies the directory to download to. The default is pic_dls</p>
        <p><span class="color1">[-f] </span>Allows you to use a file of search terms.</p>
        <p> <span class="color1">imagenetdl.py [-h] [-d DIRECTORY] [-t THREADS] [-f] search_term</span></p>
      <p><strong><u>Examples</u></strong></p>
      <blockquote>
        <p><span class="color1">python imagenetdl.py -f list.txt</span></p>
        <p>This  means that it will look for a list of search terms in the list.txt file. This list.txt file has one search term per line (see the example_list.txt) file. They will all be compiled together.</p>
        <p><span class="color1">python imagenetdl.py -d my_dir -f list.txt</span></p>
        <p>The above will use the same list from the example above, but will download everything to &quot;my_dir.&quot; If the </p>
        <p><span class="color1">python imagenetdl.py -d my_dir -t 100 -f list.txt</span></p>
        <p>This will do the same thing as above but allow a maxium of 100 threads.</p>
        </blockquote>
      <p><strong><u>Known Issues</u></strong></p>
      <p>There are a few problems with this code, aside from not having all the error-checking it place. So, if you decide to intentionally try to crash it I'm sure you'll succeed.</p>
      <p>Beyond that, there is the issues with the ImageNET files themselves, which are skewed towards using flickr.com for their downloads. In order not to hammer a particular server and get IP banned there is a delay between downloads from each server. When the list is sorted and the files beginning to be downloaded, you'll notice that after the other domains have completed you'll get a single thread pulling from flickr. This thread can run a long time unfortunately. To better balance things there is a quick hack in the counts for domains that excludes flickr.com from the count which defines how many threads there will be.</p>
      <p>&nbsp;</p></td>
    </tr>
  </table>
</div>
<p>&nbsp;</p>
</body>
</html>
